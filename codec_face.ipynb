{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ToDo\n",
    " * Generate plot of psnr to epoch\n",
    " * Calculate ssim and plot over epoch\n",
    " * Save inferred images for last epoch for each network architecture\n",
    " * Try SRCNN(9-5-5): https://github.com/kunal-visoulia/Image-Restoration-using-SRCNN/blob/master/Image%20Super%20Resolution.\n",
    " \n",
    " Litterature\n",
    " * Learning to Generate Images With Perceptual Similarity Metrics, https://arxiv.org/pdf/1511.06409.pdf\n",
    " * Image Super-Resolution Using Deep Convolutional Networks, https://arxiv.org/pdf/1501.00092.pdf\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torchmetrics.image import PeakSignalNoiseRatio\n",
    "import matplotlib.pyplot as plt\n",
    "import os, re\n",
    "from PIL import Image as PILImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify GPU present\n",
    "num_gpus = torch.cuda.device_count()\n",
    "print(f\"Number of available GPUs: {num_gpus}\")\n",
    "for gpu_id in range(num_gpus):\n",
    "    print(f\"   GPU {gpu_id}: {torch.cuda.get_device_name(gpu_id)}\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Set the seed value\n",
    "seed_value = 18\n",
    "# PyTorch\n",
    "torch.manual_seed(seed_value)\n",
    "torch.cuda.manual_seed_all(seed_value)  # For CUDA\n",
    "# Ensure that DataLoader shuffle order is reproducible\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "precision = torch.float32\n",
    "dataset_images_path = \"C:/_sw/eb_python/deep_learning/autoencoder/codec_face/dataset/eric\"\n",
    "BATCH_SIZE=16\n",
    "\n",
    "property_dataset = {\n",
    "    \"Face\": {\n",
    "        \"keyword\": \"face\",\n",
    "        \"Hin\": 384, #768, #192, #800,\n",
    "        \"Vin\": 448, #896, #224, #1000,\n",
    "        \"Cin\": 3\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the string into a list of strings and integers that is naturally sortable.\n",
    "def natural_sort_key(s):\n",
    "    return [int(text) if text.isdigit() else text.lower() for text in re.split('([0-9]+)', s)]\n",
    "\n",
    "def ImportDataset_images(path, device, precision, parameters):\n",
    "\n",
    "    # Filter for files that have the .png extension and include the specific word\n",
    "    all_files = os.listdir(path)\n",
    "    filtered_files = [file for file in all_files if file.endswith('.png') and parameters[\"keyword\"] in file]\n",
    "    filtered_files.sort(key=natural_sort_key)   # Sort using the natural sort key\n",
    "    print(\"   \" + str(len(filtered_files)) + \" files found with keyword: \" + parameters[\"keyword\"])\n",
    "\n",
    "    images_list = []\n",
    "    transform = transforms.Compose([\n",
    "            transforms.Resize((parameters[\"Vin\"], parameters[\"Hin\"])),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5), (0.5))\n",
    "        ])\n",
    "    \n",
    "    for index, file in enumerate(filtered_files):\n",
    "        print(\"\\r   Image #\" + str(index + 1) + \"/\" + str(len(filtered_files)), end=\"\")\n",
    "        image_path = os.path.join(path, f'{parameters[\"keyword\"]}_picture_{index}.png')\n",
    "        image = PILImage.open(image_path)\n",
    "        images_list.append(transform(image))\n",
    "        if index == 3000: #3001: #1001: #32 * 6 - 1:\n",
    "            break\n",
    "\n",
    "    data = torch.stack(images_list)\n",
    "    data = data.to(device)\n",
    "    data = data.to(precision)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_img_face = ImportDataset_images(dataset_images_path, \"cpu\", precision, property_dataset[\"Face\"])\n",
    "data_loader = torch.utils.data.DataLoader(datasets_img_face, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "dataiter = iter(data_loader)\n",
    "images = next(dataiter)\n",
    "print(\"Min: \" + str(torch.min(images))  +\" - Max: \" + str(torch.max(images)))\n",
    "\n",
    "datasets_img_face.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C(ch16 k3 s1 p1)R C(ch32 k3 s1 p1)BN:R C(ch64 k3 s1 p1)BN:R C(ch128 k3 s1 p1)BN:R C(ch256 k3 s1 p1)BN:R C(ch512 k3 s1 p1)BN:R C(ch1024 k5)BN:R\n",
    "class Autoencoder_Conv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # N, 3, 896, 768\n",
    "        self.enc_conv1 = nn.Conv2d(3, 16, 3, stride=1, padding=1, bias = False)       # -> N, 16, 448, 384\n",
    "        self.enc_bn1 = nn.BatchNorm2d(16)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.enc_conv2 = nn.Conv2d(16, 32, 3, stride=1, padding=1, bias = False)      # -> N, 32, 224, 192\n",
    "        self.enc_bn2 = nn.BatchNorm2d(32)\n",
    "        self.enc_conv3 = nn.Conv2d(32, 64, 3, stride=1, padding=1, bias = False)       # -> N, 64, 112, 96\n",
    "        self.enc_bn3 = nn.BatchNorm2d(64)\n",
    "        self.enc_conv4 = nn.Conv2d(64, 128, 3, stride=1, padding=1, bias = False)      # -> N, 128, 56, 48\n",
    "        self.enc_bn4 = nn.BatchNorm2d(128)\n",
    "        self.enc_conv5 = nn.Conv2d(128, 256, 3, stride=1, padding=1, bias = False)      # -> N, 256, 28, 24\n",
    "        self.enc_bn5 = nn.BatchNorm2d(256)\n",
    "        self.enc_conv6 = nn.Conv2d(256, 512, 3, stride=1, padding=1, bias = False)     # -> N, 512, 14, 12\n",
    "        self.enc_bn6 = nn.BatchNorm2d(512)\n",
    "        self.enc_conv7 = nn.Conv2d(512, 1024, 5, bias = False)    # -> N, 1024, 7, 6\n",
    "        self.enc_bn7 = nn.BatchNorm2d(1024)\n",
    "\n",
    "        self.fc1 = nn.Linear(1024 * 3 * 2, 100)\n",
    "        self.fc2 = nn.Linear(100, 1024 * 3 * 2)\n",
    "\n",
    "        # N, 2048, 3, 2\n",
    "        self.dec_convtrans1 = nn.ConvTranspose2d(1024, 512, 5)       # -> N, 1024, 7, 6\n",
    "        self.dec_convtrans3 = nn.ConvTranspose2d(512, 256, 3, stride=2, padding=1, output_padding=1)    # N, 256, 28, 14\n",
    "        self.dec_convtrans4 = nn.ConvTranspose2d(256, 128, 3, stride=2, padding=1, output_padding=1)    # N, 128, 56, 48\n",
    "        self.dec_convtrans5 = nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1)    # N, 64, 112, 96\n",
    "        self.dec_convtrans6 = nn.ConvTranspose2d(64, 32, 3, stride=2, padding=1, output_padding=1)    # N, 32, 224, 192\n",
    "        self.dec_convtrans7 = nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1)    # N, 16, 448, 384\n",
    "        self.dec_convtrans8 = nn.ConvTranspose2d(16, 3, 3, stride=2, padding=1, output_padding=1)    # N, 3, 896, 768\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x = self.maxpool(self.relu(self.enc_bn1(self.enc_conv1(x))))\n",
    "        x = self.maxpool(self.relu(self.enc_bn2(self.enc_conv2(x))))\n",
    "        x = self.maxpool(self.relu(self.enc_bn3(self.enc_conv3(x))))\n",
    "        x = self.maxpool(self.relu(self.enc_bn4(self.enc_conv4(x))))\n",
    "        x = self.maxpool(self.relu(self.enc_bn5(self.enc_conv5(x))))\n",
    "        x = self.maxpool(self.relu(self.enc_bn6(self.enc_conv6(x))))\n",
    "        x = self.relu(self.enc_bn7(self.enc_conv7(x)))\n",
    "\n",
    "        # Bottleneck\n",
    "        x = x.view(-1, 1024 * 3 * 2)     # Reshape input to [batch_size, 2048 * 3 * 2]\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = x.view(-1, 1024, 3, 2)     # Reshape input to [batch_size, 2048, 3, 2]\n",
    "\n",
    "        # Decoder\n",
    "        x = F.relu(self.dec_convtrans1(x))\n",
    "        x = F.relu(self.dec_convtrans3(x))\n",
    "        x = F.relu(self.dec_convtrans4(x))\n",
    "        x = F.relu(self.dec_convtrans5(x))\n",
    "        x = F.relu(self.dec_convtrans6(x))\n",
    "        x = F.relu(self.dec_convtrans7(x))\n",
    "        #x = F.sigmoid(self.dec_convtrans8(x))\n",
    "        x = F.tanh(self.dec_convtrans8(x))\n",
    "        \n",
    "        return x    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C(ch16 k3 s1 p1)R C(ch32 k3 s1 p1)BN:R C(ch64 k3 s1 p1)BN:R C(ch128 k3 s1 p1)BN:R C(ch256 k3 s1 p1)BN:R C(ch512 k3 s1 p1)BN:R C(ch1024 k3 s1 p1)BN:R C(ch2048 k5)BN:R\n",
    "class Autoencoder_Conv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # N, 3, 896, 768\n",
    "        self.enc_conv1 = nn.Conv2d(3, 16, 3, stride=1, padding=1, bias = False)       # -> N, 16, 448, 384\n",
    "        self.enc_bn1 = nn.BatchNorm2d(16)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.enc_conv2 = nn.Conv2d(16, 32, 3, stride=1, padding=1, bias = False)      # -> N, 32, 224, 192\n",
    "        self.enc_bn2 = nn.BatchNorm2d(32)\n",
    "        self.enc_conv3 = nn.Conv2d(32, 64, 3, stride=1, padding=1, bias = False)       # -> N, 64, 112, 96\n",
    "        self.enc_bn3 = nn.BatchNorm2d(64)\n",
    "        self.enc_conv4 = nn.Conv2d(64, 128, 3, stride=1, padding=1, bias = False)      # -> N, 128, 56, 48\n",
    "        self.enc_bn4 = nn.BatchNorm2d(128)\n",
    "        self.enc_conv5 = nn.Conv2d(128, 256, 3, stride=1, padding=1, bias = False)      # -> N, 256, 28, 24\n",
    "        self.enc_bn5 = nn.BatchNorm2d(256)\n",
    "        self.enc_conv6 = nn.Conv2d(256, 512, 3, stride=1, padding=1, bias = False)     # -> N, 512, 14, 12\n",
    "        self.enc_bn6 = nn.BatchNorm2d(512)\n",
    "        self.enc_conv7 = nn.Conv2d(512, 1024, 3, stride=1, padding=1, bias = False)    # -> N, 1024, 7, 6\n",
    "        self.enc_bn7 = nn.BatchNorm2d(1024)\n",
    "        self.enc_conv8 = nn.Conv2d(1024, 2048, 5)     # -> N, 2048, 3, 2\n",
    "        self.enc_bn8 = nn.BatchNorm2d(2048)\n",
    "\n",
    "        self.fc1 = nn.Linear(2048 * 3 * 2, 100)\n",
    "        self.fc2 = nn.Linear(100, 2048 * 3 * 2)\n",
    "\n",
    "        # N, 2048, 3, 2\n",
    "        self.dec_convtrans1 = nn.ConvTranspose2d(2048, 1024, 5)       # -> N, 1024, 7, 6\n",
    "        self.dec_convtrans2 = nn.ConvTranspose2d(1024, 512, 3, stride=2, padding=1, output_padding=1)    # N, 512, 14, 12\n",
    "        self.dec_convtrans3 = nn.ConvTranspose2d(512, 256, 3, stride=2, padding=1, output_padding=1)    # N, 256, 28, 14\n",
    "        self.dec_convtrans4 = nn.ConvTranspose2d(256, 128, 3, stride=2, padding=1, output_padding=1)    # N, 128, 56, 48\n",
    "        self.dec_convtrans5 = nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1)    # N, 64, 112, 96\n",
    "        self.dec_convtrans6 = nn.ConvTranspose2d(64, 32, 3, stride=2, padding=1, output_padding=1)    # N, 32, 224, 192\n",
    "        self.dec_convtrans7 = nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1)    # N, 16, 448, 384\n",
    "        self.dec_convtrans8 = nn.ConvTranspose2d(16, 3, 3, stride=2, padding=1, output_padding=1)    # N, 3, 896, 768\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x = self.maxpool(self.relu(self.enc_bn1(self.enc_conv1(x))))\n",
    "        x = self.maxpool(self.relu(self.enc_bn2(self.enc_conv2(x))))\n",
    "        x = self.maxpool(self.relu(self.enc_bn3(self.enc_conv3(x))))\n",
    "        x = self.maxpool(self.relu(self.enc_bn4(self.enc_conv4(x))))\n",
    "        x = self.maxpool(self.relu(self.enc_bn5(self.enc_conv5(x))))\n",
    "        x = self.maxpool(self.relu(self.enc_bn6(self.enc_conv6(x))))\n",
    "        x = self.maxpool(self.relu(self.enc_bn7(self.enc_conv7(x))))\n",
    "        x = self.relu(self.enc_bn8(self.enc_conv8(x)))\n",
    "\n",
    "        # Bottleneck\n",
    "        x = x.view(-1, 2048 * 3 * 2)     # Reshape input to [batch_size, 2048 * 3 * 2]\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = x.view(-1, 2048, 3, 2)     # Reshape input to [batch_size, 2048, 3, 2]\n",
    "\n",
    "        # Decoder\n",
    "        x = F.relu(self.dec_convtrans1(x))\n",
    "        x = F.relu(self.dec_convtrans2(x))\n",
    "        x = F.relu(self.dec_convtrans3(x))\n",
    "        x = F.relu(self.dec_convtrans4(x))\n",
    "        x = F.relu(self.dec_convtrans5(x))\n",
    "        x = F.relu(self.dec_convtrans6(x))\n",
    "        x = F.relu(self.dec_convtrans7(x))\n",
    "        #x = F.sigmoid(self.dec_convtrans8(x))\n",
    "        x = F.tanh(self.dec_convtrans8(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Autoencoder_Conv().to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                             lr=1e-3, \n",
    "                             weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train model ###\n",
    "\n",
    "num_epochs = 100\n",
    "dataiter = iter(data_loader)\n",
    "val_imgs = next(dataiter)       # Reuse same images for validation\n",
    "val_imgs = val_imgs.to(device)\n",
    "outputs = []\n",
    "\n",
    "psnr_metric = PeakSignalNoiseRatio()    # Initialize the PSNR metric object\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    batch = 1\n",
    "    for (train_imgs) in data_loader:\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        train_imgs = train_imgs.to(device)\n",
    "        train_out = model(train_imgs)\n",
    "        loss = criterion(train_out, train_imgs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch%1 == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():  # Ensure no gradients are computed for validation\n",
    "                val_out = model(val_imgs)\n",
    "                psnr_value = psnr_metric(val_imgs.cpu(), val_out.cpu())   # Compute PSNR\n",
    "                print(f'Epoch:{epoch+1}, Batch:{batch+1}, Loss:{loss.item():.4f}, PSNR:{psnr_value:.2f}dB')\n",
    "                #outputs.append((epoch, batch, val_imgs.cpu(), val_out.detach().cpu(), psnr_value))      # detach() removes the tensor from the computation graph\n",
    "                outputs.append((epoch, batch, psnr_value, loss.item()))\n",
    "        batch += 1\n",
    "\n",
    "num_batches = batch - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generage image of ground truth and inferred data for each batch of each epoch ###\n",
    "\n",
    "lst_number = [0, 1, 2, 3, 4]    # Index for the 5 images to be used for inferrence\n",
    "\n",
    "for idx_epoch in range(0, num_epochs, 1):\n",
    "    for idx_batch in range(0, num_batches//25, 1):\n",
    "        plt.figure(figsize=(6, 5))\n",
    "        epoch = outputs[idx_epoch*num_batches//25+idx_batch][0]\n",
    "        batch = outputs[idx_epoch*num_batches//25+idx_batch][1]\n",
    "        imgs = outputs[idx_epoch*num_batches//25+idx_batch][2].detach().numpy()\n",
    "        recon = outputs[idx_epoch*num_batches//25+idx_batch][3].detach().numpy()\n",
    "\n",
    "        for i in range(5):\n",
    "            plt.subplot(2, 5, i+1)\n",
    "            img = imgs[lst_number[i]].transpose(1, 2, 0)    # Reordering dimension of tensor from (channel, width, height) to (width, height, channel)\n",
    "            img = (img - img.min()) / (img.max() - img.min())   # Normalize values from 0 to 1\n",
    "            #print(\"GT: max: \" + str(img.max()) + \" - min: \" + str(img.min()))\n",
    "            plt.imshow(img)\n",
    "            plt.axis('off')\n",
    "\n",
    "        for i in range(5):\n",
    "            plt.subplot(2, 5, 5+i+1) # row_length + i + 1\n",
    "            img = recon[lst_number[i]].transpose(1, 2, 0)    # Reordering dimension of tensor from (channel, width, height) to (width, height, channel)\n",
    "            img = (img - img.min()) / (img.max() - img.min())   # Normalize values from 0 to 1\n",
    "            #print(\"OUT: max: \" + str(img.max()) + \" - min: \" + str(img.min()))\n",
    "            plt.imshow(img)\n",
    "            plt.axis('off')\n",
    "        \n",
    "        plt.suptitle('Epoch #' + str(epoch) + ' - Batch #' + str(batch) + \"\\nC(ch16 k3 s1 p1)R C(ch32 k3 s1 p1)R C(ch64 k3 s1 p1)R C(ch128 k3 s1 p1)R C(ch256 k3 s1 p1)R C(ch512 k3 s1 p1 + Bottleneck)\", fontsize=6)\n",
    "        #plt.suptitle('Epoch #' + str(epoch) + ' - Batch #' + str(batch) + \"\\nC(ch16 k3 s1 p1)R C(ch32 k3 s1 p1)R C(ch64 k3 s1 p1)R C(ch128 k3 s1 p1)R C(ch256 k5)\", fontsize=16)\n",
    "        plt.savefig('results/_temp/face_autoencoder_epoch' + str(epoch) + '_batch' + str(batch).zfill(3) + '.png', format='png', dpi=300)\n",
    "        plt.close()  # Close the figure to avoid displaying it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate video off images ###\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Directory containing images\n",
    "img_dir = \"results/C(ch16 k3 s1 p1)R C(ch32 k3 s1 p1)R C(ch64 k3 s1 p1)R C(ch128 k3 s1 p1)R C(ch256 k3 s1 p1)R C(ch512 k5)\"  # Enter Directory of all images\n",
    "data_path = os.path.join(img_dir, '*g')  # Assuming images are in JPG or PNG format, adjust the wildcard as needed\n",
    "files = sorted(glob.glob(data_path))  # Sort files by filename\n",
    "\n",
    "# Frame properties\n",
    "RATIO = 1\n",
    "frame = cv2.imread(files[0])\n",
    "height, width, layers = frame.shape\n",
    "size = (width//RATIO, height//RATIO)\n",
    "\n",
    "# Video properties\n",
    "out = cv2.VideoWriter('results/C(ch16 k3 s1 p1)R C(ch32 k3 s1 p1)R C(ch64 k3 s1 p1)R C(ch128 k3 s1 p1)R C(ch256 k3 s1 p1)R C(ch512 k5)/face_autoencoder.avi', cv2.VideoWriter_fourcc(*'DIVX'), 10, size)  # 1 is the FPS, adjust as needed\n",
    "\n",
    "for f in files:\n",
    "    img = cv2.imread(f)\n",
    "    img = cv2.resize(img, size)\n",
    "    out.write(img)\n",
    "\n",
    "out.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Standard",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
